{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesosn 21\n",
    "\n",
    "[Course Repo](https://github.com/fastai/course22p2)\n",
    "\n",
    "\n",
    "Breif outline\n",
    "\n",
    "-  Jono: Demo of WandB.  (notebook 21_cifar10_and_wandb.ipynb) \n",
    "    - Uses CFAR10 instead of fashion mnist.  The tools still work. \n",
    "    - Weights and Biases (WandB) mointoring. Using [WandB](https://wandb.ai/site) for monitoring and tracking of model performance. \n",
    "    - You call logging functions in your code to log metrics, hyperparameters, and other data to the WandB server, and then you can view and compare these results in the WandB dashboard.\n",
    "    - You can also use WandB to log models, code and more.\n",
    "    - Jono implements a WandB callback in a few lines to implment this!\n",
    "    - Jeremy says he doesn't use this (intentionally) because he worries about just doing wide sweeps of hyperparameters.  He prefers to do a more focused search.\n",
    "\n",
    "- 20:50 Metrics  \n",
    "\n",
    "\n",
    "\n",
    "## WandB demo\n",
    "\n",
    "Jono: Demo of WandB.  (notebook 21_cifar10_and_wandb.ipynb) \n",
    "\n",
    "- Uses CFAR10 instead of fashion mnist.  The tools still work. \n",
    "- Weights and Biases (WandB) mointoring. Using [WandB](https://wandb.ai/site) for monitoring and tracking of model performance. \n",
    "- You call logging functions in your code to log metrics, hyperparameters, and other data to the WandB server, and then you can view and compare these results in the WandB dashboard.\n",
    "- You can also use WandB to log models, code and more.\n",
    "- Jono implements a WandB callback in a few lines to implment this!\n",
    "- Jeremy says he doesn't use this (intentionally) because he worries about just doing wide sweeps of hyperparameters.  He prefers to do a more focused search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FID METRIC:\n",
    "\n",
    "- Frechet inception distance (FID), demo in notbout 18_Fid.ipynb  Uses DDPM model from previous lesson. \n",
    "   - FID is a metric for generative models.\n",
    "   - It is a measure of how well the generated images are similar.\n",
    "   - Looks to see what the 'typical' final layer applications look like for a set up images.\n",
    "\n",
    "At 31:00 he discovers \"a bug\" in the images scaline.\n",
    "\n",
    "Discusses several ways to grab the output of the gloabl average pooling layer.\n",
    "\n",
    "- Hooks\n",
    "- Deleting the rest of the layers. \n",
    "- other ways....?\n",
    "\n",
    "- compares means and covariance matrix of the global pooling layer (accross the samples/training data) for a classification model for the test images vs the generated images.  Correlation mans for example that images with one feature will have another feature.  So you want the generated images to have the same means and covariance matrix as the training data.\n",
    "\n",
    "Show example for the case at hand, 512 channels. (around 38 minutes)\n",
    "\n",
    "- The FID score is the distance between the means and covariance matrix.  \n",
    "- Needs matrix squar root of hte product of the covariance matrices ..  \n",
    "\n",
    "$$\n",
    "d_{F}(\\mathcal N(\\mu, \\Sigma), \\mathcal N(\\mu', \\Sigma'))^2 = \\lVert \\mu - \\mu' \\rVert^2_2 + \\operatorname{tr}\\left(\\Sigma + \\Sigma' -2\\left(\\Sigma \\Sigma'  \\right)^\\frac{1}{2} \\right)\n",
    "$$\n",
    "\n",
    "- called Inception because it uses the Inception model in the more normal use case.\n",
    "\n",
    "- He gets 33.8 .  Whats that supposed to tell us?\n",
    "\n",
    "- Primary caveat is that you cant really compare FID scores between different sized data sets. (Biased somehow... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KID 50:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KID Kernal inception distance.   \n",
    "\n",
    "- Uses the features directly not the means accross the set. \n",
    "- \"The math doesnt matter\" \n",
    "- Measure of simularity between the distribtuions of the features.   \n",
    "- Has low bias but high variance.\n",
    "\n",
    "Jeramy creates a class for thsi that returns both FID and KID.  He shows for example how the images improve during the denoising process. KID and FID do look the same. \n",
    "\n",
    "Jeremy also looks at the 'real' fid using the real FID . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the scaling bug 1:00\n",
    "\n",
    "- Jeremy noticed that back in the DDPM_v2 notebook, the images were scaled from 0 to 1 instad of -1 to 1.   He fixes this:\n",
    "```\n",
    "@inplace\n",
    "def transformi(b): b[xl] = [F.pad(TF.to_tensor(o), (2,2,2,2))*2-1 for o in b[xl]]\n",
    "```\n",
    "\n",
    "- This makes everything worse, so he spent two days trying to find the other bug that must be responsble and was being offset by this bug.\n",
    "\n",
    "- In the end he finds no relavent bug and asks: why is it a bug to scale from 0 to 1? Just because everyone else does it?  He tried it ny just subtracting 0.5 which keeps the range the same (smaller then normal). This leads to DDBM_v3. This is an improvement to the model, even accoring to the FID score.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule experiments 1:09\n",
    "\n",
    "* uses 19 DDPM_v3 notebook.  \n",
    "\n",
    "* As part of his debugging he started to question everything, for example the $\\beta$ schedule\n",
    "\n",
    "* Tested Cosine squedule vs linear schedule to compare them.  Remember that $\\bar{\\alpha}$ is what really matters.  \n",
    "\n",
    "Note that the linear score has a long part of the time when the $\\bar{\\alpha}$ is near zero.  So he also tried decreasing $\\beta_{max}$. In fact the curves are similar in that case. So in the next version he changed $\\beta_{max}$ to 0.01   Results do look better. He also changed the model by making it bigger and training for longer.\n",
    "\n",
    "Fid is nearly as good as real image. \n",
    "\n",
    "\n",
    "* SKip sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "205 % 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "106//100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[949, 959, 969, 979, 989, 999]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps  = 1000\n",
    "[t for t in range(n_steps) if (t+101)%((t+101)//100)==0][290:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def sample2(model, sz):\n",
    "    ps = next(model.parameters())\n",
    "    x_t = torch.randn(sz).to(ps)\n",
    "    sample_at = {t for t in range(n_steps) if (t+101)%((t+101)//100)==0}\n",
    "    preds = []\n",
    "    for t in reversed(range(n_steps)):\n",
    "        t_batch = torch.full((x_t.shape[0],), t, device=ps.device, dtype=torch.long)\n",
    "        z = (torch.randn(x_t.shape) if t > 0 else torch.zeros(x_t.shape)).to(ps)\n",
    "        ᾱ_t1 = alphabar[t-1]  if t > 0 else torch.tensor(1)\n",
    "        b̄_t = 1-alphabar[t]\n",
    "        b̄_t1 = 1-ᾱ_t1\n",
    "        if t in sample_at: noise = model((x_t, t_batch))\n",
    "        x_0_hat = ((x_t - b̄_t.sqrt() * noise)/alphabar[t].sqrt())\n",
    "        x_t = x_0_hat * ᾱ_t1.sqrt()*(1-alpha[t])/b̄_t + x_t * alpha[t].sqrt()*b̄_t1/b̄_t + sigma[t]*z\n",
    "        if t in sample_at: preds.append(x_t.float().cpu())\n",
    "    return preds\n",
    "\n",
    "    # And he has another that skipps even more less severly\n",
    "\n",
    "    # FID SCORE TILL pretty good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### 1:20  DDIM\n",
    "\n",
    "Whats the best paper for faster generation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdl_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
