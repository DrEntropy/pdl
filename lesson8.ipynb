{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 8 : Convolution networks\n",
    "\n",
    "### But FIRST - finish up Collaborative filtering!\n",
    "\n",
    "I included notes on the rest of Chapter 8  in the previous lesson because I had no idea he was going to continue on in this lesson. \n",
    "\n",
    "For reference he goes over:\n",
    "\n",
    "* Creating your own embedding layer\n",
    "\n",
    "* Intepreting embeddings and biases \n",
    "\n",
    "* Using fastai's `collab_learner` implementation\n",
    "\n",
    "* Embedding distances \n",
    "\n",
    "* Deep learning for collab filtering\n",
    "\n",
    "\n",
    "### Embeddings for NLP (30:30)\n",
    "\n",
    "* Discussion of how embeddings are used words, which are just a large categorical variable (the vocab)\n",
    "\n",
    "* The neural net only sees the embeddings, which it learns.\n",
    "\n",
    "\n",
    "### Embeddings for Tabular\n",
    "\n",
    "* As mentioned (i think?) before we can also turn any categorical into an embedding, for example those that often appear in tabular data. \n",
    "\n",
    "* This is done in chapter 9 in the book.\n",
    "\n",
    "* Guo, Cheng, and Felix Berkhahn. 2016. “Entity Embeddings of Categorical Variables.” arXiv. https://doi.org/10.48550/arXiv.1604.06737.\n",
    "\n",
    "* Guo et. al. also combined deep learning embeddings with boosted trees (i.e. also feeding the embeddings into decision tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNS\n",
    "\n",
    "Video at 44:30\n",
    "\n",
    "* Based partly on Chapter 13 in the book.\n",
    "\n",
    "\n",
    "#### Convolutions and pooling\n",
    "* First he presents convolutions in excel.  Mentions that MaxPooling is not as common and modern visual learners use stride > 1 (typically 2?) and average pooling at the end. \n",
    "\n",
    "* Fastai uses \"Concat pooling\" and concatenates the average and max pooling layers at the end.\n",
    "\n",
    "* Points out that a convolution layer is really just a matrix multiplication: \n",
    "   * Flatten the input into a vector\n",
    "   * Now the convolution can be written as a matrix multiplying the vector, except that the is constrained: Many of the weights are zero, and the rest are shared.\n",
    "   * This is shown in Chapter 13 of the book.\n",
    "\n",
    "\n",
    "####  Dropout layers\n",
    "\n",
    "* Shows how dropout works in excel, corrupting the activations randomly for each batch. \n",
    "\n",
    "* This is a regularization technique that helps prevent overfitting.\n",
    "\n",
    "* The idea is that a human can look at the corrupted image and still see what it was, and a neural net should be able to as well. This forces the model to the learn the representation and not just memorize the data (overfitting).\n",
    "\n",
    "\n",
    "#### Activation functions\n",
    "\n",
    "* Pretty much any nonlinearity can be used as an activation function.\n",
    "\n",
    "* ReLU is the most common these days as it is fast, but others are commonly used as well.. tanh, sigmoid, etc.\n",
    "\n",
    "\n",
    "\n",
    "## WHAT NOW? \n",
    "\n",
    "*  Write - Code, papers, blog posts, etc.\n",
    "\n",
    "* Help - Forums, StackOverflow, etc.\n",
    "\n",
    "* Gather - Book clubs, meetups, study groups\n",
    "\n",
    "* Build - Apps, Work Projects, Libraries\n",
    "\n",
    "* Go on to part too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 13\n",
    "\n",
    "* The book and the lecutre overlap quite a bit in concept.\n",
    "\n",
    "* The book however also gives some pytorch examples of setting up a CNN for MNIST\n",
    "\n",
    "* Although I have done this before, I think I will reproduce it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MNIST dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_path = './data'\n",
    "mnist = datasets.MNIST(data_path, train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first image is a 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3556da850>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "data_loader = DataLoader(mnist, batch_size=32, shuffle=True)\n",
    "\n",
    "# pull in a sample image\n",
    "data_iter = iter(data_loader)\n",
    "images, labels = next(data_iter)\n",
    "print(f\"first image is a {labels[0]}\")\n",
    "# plot the fist image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok lets build a simple model to classify MNIST digits using a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN using stride of 2 to downsample until we reach 1x1\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = torch.relu(self.conv5(x))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 128)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, step 0, loss 2.2970962524414062\n",
      "epoch 0, step 100, loss 0.529944658279419\n",
      "epoch 0, step 200, loss 0.21718564629554749\n",
      "epoch 0, step 300, loss 0.2556946575641632\n",
      "epoch 0, step 400, loss 0.21101044118404388\n",
      "epoch 0, step 500, loss 0.12730374932289124\n",
      "epoch 0, step 600, loss 0.14507035911083221\n",
      "epoch 0, step 700, loss 0.22321510314941406\n",
      "epoch 0, step 800, loss 0.03843311965465546\n",
      "epoch 0, step 900, loss 0.2069709599018097\n",
      "epoch 0, step 1000, loss 0.16211853921413422\n",
      "epoch 0, step 1100, loss 0.027688318863511086\n",
      "epoch 0, step 1200, loss 0.015369717963039875\n",
      "epoch 0, step 1300, loss 0.03924035653471947\n",
      "epoch 0, step 1400, loss 0.2293858379125595\n",
      "epoch 0, step 1500, loss 0.07648778706789017\n",
      "epoch 0, step 1600, loss 0.04399525746703148\n",
      "epoch 0, step 1700, loss 0.007497603073716164\n",
      "epoch 0, step 1800, loss 0.006861202884465456\n",
      "epoch 1, step 0, loss 0.02264256961643696\n",
      "epoch 1, step 100, loss 0.04764539375901222\n",
      "epoch 1, step 200, loss 0.01589866355061531\n",
      "epoch 1, step 300, loss 0.07090359926223755\n",
      "epoch 1, step 400, loss 0.024592598900198936\n",
      "epoch 1, step 500, loss 0.11376626789569855\n",
      "epoch 1, step 600, loss 0.002082922263070941\n",
      "epoch 1, step 700, loss 0.04276108741760254\n",
      "epoch 1, step 800, loss 0.18935012817382812\n",
      "epoch 1, step 900, loss 0.08605829626321793\n",
      "epoch 1, step 1000, loss 0.052331969141960144\n",
      "epoch 1, step 1100, loss 0.020062511786818504\n",
      "epoch 1, step 1200, loss 0.07940813153982162\n",
      "epoch 1, step 1300, loss 0.013754516839981079\n",
      "epoch 1, step 1400, loss 0.03181834518909454\n",
      "epoch 1, step 1500, loss 0.04282267391681671\n",
      "epoch 1, step 1600, loss 0.14277426898479462\n",
      "epoch 1, step 1700, loss 0.38947179913520813\n",
      "epoch 1, step 1800, loss 0.025226246565580368\n",
      "epoch 2, step 0, loss 0.0101753706112504\n",
      "epoch 2, step 100, loss 0.07488954812288284\n",
      "epoch 2, step 200, loss 0.004859317094087601\n",
      "epoch 2, step 300, loss 0.008353865705430508\n",
      "epoch 2, step 400, loss 0.027062145993113518\n",
      "epoch 2, step 500, loss 0.004113832488656044\n",
      "epoch 2, step 600, loss 0.14071527123451233\n",
      "epoch 2, step 700, loss 0.01928788423538208\n",
      "epoch 2, step 800, loss 0.0149112893268466\n",
      "epoch 2, step 900, loss 0.01636776700615883\n",
      "epoch 2, step 1000, loss 0.0005661343457177281\n",
      "epoch 2, step 1100, loss 0.0032032772433012724\n",
      "epoch 2, step 1200, loss 0.008379029110074043\n",
      "epoch 2, step 1300, loss 0.024283820763230324\n",
      "epoch 2, step 1400, loss 0.000345139967976138\n",
      "epoch 2, step 1500, loss 0.00466805137693882\n",
      "epoch 2, step 1600, loss 0.09463124722242355\n",
      "epoch 2, step 1700, loss 0.0024557113647460938\n",
      "epoch 2, step 1800, loss 0.07104561477899551\n"
     ]
    }
   ],
   "source": [
    "# simple training loop\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(3):\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f\"epoch {epoch}, step {i}, loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(mnist_test, batch_size=32)\n",
    "correct = sum((torch.argmax(model(images), dim=1) == labels).sum().item() \n",
    "              for images, labels in test_loader)\n",
    "total = len(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9849\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy: {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdl_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
