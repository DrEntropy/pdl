{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 8 : Convolution networks\n",
    "\n",
    "### But FIRST - finish up Collaborative filtering!\n",
    "\n",
    "I included notes on the rest of Chapter 8  in the previous lesson because I had no idea he was going to continue on in this lesson. \n",
    "\n",
    "For reference he goes over:\n",
    "\n",
    "* Creating your own embedding layer\n",
    "\n",
    "* Intepreting embeddings and biases \n",
    "\n",
    "* Using fastai's `collab_learner` implementation\n",
    "\n",
    "* Embedding distances \n",
    "\n",
    "* Deep learning for collab filtering\n",
    "\n",
    "\n",
    "### Embeddings for NLP (30:30)\n",
    "\n",
    "* Discussion of how embeddings are used words, which are just a large categorical variable (the vocab)\n",
    "\n",
    "* The neural net only sees the embeddings, which it learns.\n",
    "\n",
    "\n",
    "### Embeddings for Tabular\n",
    "\n",
    "* As mentioned (i think?) before we can also turn any categorical into an embedding, for example those that often appear in tabular data. \n",
    "\n",
    "* This is done in chapter 9 in the book.\n",
    "\n",
    "* Guo, Cheng, and Felix Berkhahn. 2016. “Entity Embeddings of Categorical Variables.” arXiv. https://doi.org/10.48550/arXiv.1604.06737.\n",
    "\n",
    "* Guo et. al. also combined deep learning embeddings with boosted trees (i.e. also feeding the embeddings into decision tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNS\n",
    "\n",
    "Video at 44:30\n",
    "\n",
    "* Based partly on Chapter 13 in the book.\n",
    "\n",
    "\n",
    "#### Convolutions and pooling\n",
    "* First he presents convolutions in excel.  Mentions that MaxPooling is not as common and modern visual learners use stride > 1 (typically 2?) and average pooling at the end. \n",
    "\n",
    "* Fastai uses \"Concat pooling\" and concatenates the average and max pooling layers at the end.\n",
    "\n",
    "* Points out that a convolution layer is really just a matrix multiplication: \n",
    "   * Flatten the input into a vector\n",
    "   * Now the convolution can be written as a matrix multiplying the vector, except that the is constrained: Many of the weights are zero, and the rest are shared.\n",
    "   * This is shown in Chapter 13 of the book.\n",
    "\n",
    "\n",
    "####  Dropout layers\n",
    "\n",
    "* Shows how dropout works in excel, corrupting the activations randomly for each batch. \n",
    "\n",
    "* This is a regularization technique that helps prevent overfitting.\n",
    "\n",
    "* The idea is that a human can look at the corrupted image and still see what it was, and a neural net should be able to as well. This forces the model to the learn the representation and not just memorize the data (overfitting).\n",
    "\n",
    "\n",
    "#### Activation functions\n",
    "\n",
    "* Pretty much any nonlinearity can be used as an activation function.\n",
    "\n",
    "* ReLU is the most common these days as it is fast, but others are commonly used as well.. tanh, sigmoid, etc.\n",
    "\n",
    "\n",
    "\n",
    "## WHAT NOW? \n",
    "\n",
    "*  Write - Code, papers, blog posts, etc.\n",
    "\n",
    "* Help - Forums, StackOverflow, etc.\n",
    "\n",
    "* Gather - Book clubs, meetups, study groups\n",
    "\n",
    "* Build - Apps, Work Projects, Libraries\n",
    "\n",
    "* Go on to part too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 13\n",
    "\n",
    "* The book and the lecutre overlap quite a bit in concept.\n",
    "\n",
    "* The book however also gives some pytorch examples of setting up a CNN for MNIST\n",
    "\n",
    "* Although I have done this before, I think I will reproduce it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MNIST dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_path = './data'\n",
    "mnist = datasets.MNIST(data_path, train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first image is a 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x34b2392d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "data_loader = DataLoader(mnist, batch_size=32, shuffle=True)\n",
    "\n",
    "# pull in a sample image\n",
    "data_iter = iter(data_loader)\n",
    "images, labels = next(data_iter)\n",
    "print(f\"first image is a {labels[0]}\")\n",
    "# plot the fist image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok lets build a simple model to classify MNIST digits using a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN using stride of 2 to downsample until we reach 1x1\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = torch.relu(self.conv5(x))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 128)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, step 0, loss 2.3171896934509277\n",
      "epoch 0, step 100, loss 0.4856065809726715\n",
      "epoch 0, step 200, loss 0.252500057220459\n",
      "epoch 0, step 300, loss 0.37092575430870056\n",
      "epoch 0, step 400, loss 0.6967332363128662\n",
      "epoch 0, step 500, loss 0.21403904259204865\n",
      "epoch 0, step 600, loss 0.32830095291137695\n",
      "epoch 0, step 700, loss 0.3021112382411957\n",
      "epoch 0, step 800, loss 0.40029770135879517\n",
      "epoch 0, step 900, loss 0.2357884794473648\n",
      "epoch 0, step 1000, loss 0.6242004036903381\n",
      "epoch 0, step 1100, loss 0.01730935275554657\n",
      "epoch 0, step 1200, loss 0.214797705411911\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pdl_p/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pdl_p/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pdl_p/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# simple training loop\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(3):\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f\"epoch {epoch}, step {i}, loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(mnist_test, batch_size=32)\n",
    "correct = sum((torch.argmax(model(images), dim=1) == labels).sum().item() \n",
    "              for images, labels in test_loader)\n",
    "total = len(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"accuracy: {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdl_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
