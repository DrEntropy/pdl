{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 4\n",
    "\n",
    "### Getting started with NLP for absolute beginners\n",
    "\n",
    "Recommended first doing the kaggle notebook [Getting started with NLP for absolute beginners] (https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners) \n",
    "\n",
    "  - I ran it with 'pin to original environment' on.\n",
    "\n",
    "   - It really is for beginners in that it goes through a lot of basics (like train/val/test split, and pearson correlation coefficient). I skimmed most of this and suspect most of the group will do so as well.  Note he says something not quite right about correlation and slope. $ \\beta = r \\frac{s_x}{s_y} $\n",
    "\n",
    "   - Based on the US Patent Phrase to Phrase matching competition. Uses classification in an interesting way to classify the combination of two phrases as similar, different or identical.\n",
    "\n",
    "   - The dataset consists of 'anchors' 'context' 'targets' and 'scores'.  The anchor and target are the things we want to compare (in the context 'context'), and the score is the comparison (0,.25, .5, .75, 1.0) are the possibilities.  The key trick is to turn this into a classification problem, that is to classify (regress) the following text :  \n",
    "\n",
    "   `df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor`\n",
    "\n",
    "   - Context is some code like `A47`, the CPC classification code, the subject within which the simularity is to be scored.   \n",
    "\n",
    "   - Tokenization splits the text into tokens (subword usually), and then turns the tokens into a number for each unique token (vocab). Why? Because neural nets can only use numbers! Note, you must use the right tokenizer for the model you are using. Notebook has good examples of how 'subword' looks.\n",
    "\n",
    "   - Huggingface dataset is different from pytorch dataset !  Huggingface models expect a Hugginface `dataset`, which can be created from a pandas dataframe.\n",
    "\n",
    "   - Note there are a lot of pretrained models on the [Huggingface model library](https://huggingface.co/models), and some might be trained on something close to what you want to do. In this case he is using a general use model (microsoft/deberta-v3-small) which was good starting point at that time.\n",
    "\n",
    "   - Note that they use \"AutoModelForSequenceClassification\" using num_labels =1 , so they are doing a regression (using `MSELoss()`) on the label not a classification. But it seems to work well here.  \n",
    "\n",
    "   - Key takeaways: You can get pretty good results using existing pretrained models \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video\n",
    "\n",
    "* This video doesn't use fast.ai library at all!  Just huggingface.  Huggingface is supposedly state of the art for NLP. \n",
    "\n",
    "* Video mentions that these advanced methods will be folded into fast.ai, this doesn't seem to be the case?\n",
    "\n",
    "#### ULMFit \n",
    "\n",
    "* Again approach is to finetune a pre-trained model. First part of lecture tries to make what this means more clear using the slider model from previous chapter... imagine some sliders are already close.\n",
    "\n",
    "* [ULMfit](https://arxiv.org/abs/1801.06146) - used an RNN \n",
    "\n",
    "   - Step one - use a language model pretrained on next word predictions on wikipedia. \n",
    "   - Step two - Fine tune on next workd for IMDB movie review\n",
    "   - Step three - Fine tune model on movie sentiment with a classifier head.\n",
    "\n",
    "* Nice thing is that the pretraining requires no special labels, the labels are built into the data!  Only in step three do we need labeled data.\n",
    "\n",
    "* Transformers were introduced around the time of the ULMfit. Advantages:\n",
    "   - Parallel training on GPUs\n",
    "   - No vansishing gradients\n",
    "\n",
    "* Jeremy says that transformers are not well suited to next word prediction (?? But they are! Gilbert 2018) and that they instead used masked word prediction (i.e. predict a missing word.) This is the case for many models, but also next word prediction is done.  Note that DeBerta is a variant of masked language model. \n",
    "\n",
    "* Jeremy uses CNN as an example, that it is the later layers that are task specific. Specifically, in the image case, the last layer that was used in the pretraining for classification we throw away and add on a new classification head for a specific problem, ( random matrix)  , and train that. More on how to do this in detail from scratch in part two.\n",
    "\n",
    "#### Kaggle notebook\n",
    "\n",
    "* Next video walks through the notebook, see my notes above.  He assumes the same level for the audience: Not familiar with pandas, etc. \n",
    "\n",
    "* He emphasizes that classification using NLP is very accessible and has wide application. \n",
    "\n",
    "\n",
    "#### Key libraries:\n",
    "\n",
    "* Numpy\n",
    "* Pandas\n",
    "* Matplotlib (Seaborn)\n",
    "* Pytorch (and others like sklearn and statsmodels)\n",
    "\n",
    "Recommends [Python for Data Analysis](https://wesmckinney.com/book/). The book covers mainly the first three, and touches on statsmodels and sklearn at the end.\n",
    "\n",
    "#### Aside on validation sets and metrics\n",
    "\n",
    "[How (and why) to create a good validation set](https://www.fast.ai/posts/2017-11-13-validation-sets.html)\n",
    "\n",
    "Just about being careful, and make sure your validation set validates the task you really want to do. Key example is for time series, validation should be future points.\n",
    "\n",
    "Also one must be careful not to overfit to the validation set (through hyperparameter choice or model choice). Test set should be held out until the very end!\n",
    "\n",
    "[The problem with metrics is a big problem for AI](https://www.fast.ai/posts/2019-09-24-metrics.html#:~:text=The%20problem%20with%20metrics%20is%20a%20big%20problem,environments%20...%205%20When%20Metrics%20are%20Useful%20)\n",
    "\n",
    "* Issues with metrics becoming targets (Goodhart's Law \"When a measure becomes a target, it ceases to be a good measure\")  (e.g. KPPs, SPIF's etc have unintended consequences! )\n",
    "\n",
    "* AI makes this worse (Leverage)\n",
    "\n",
    "\n",
    "### Use and Misuse of NLP\n",
    "\n",
    "* NLP is moving fast, things are possible now that are not possible are year ago!! Huge oppurtunity area.\n",
    "\n",
    "* Fake comments and articles... could influence outcomes! \n",
    "\n",
    "\n",
    "### Final question about categorical vs regression\n",
    "\n",
    "Jeremy mentions that yes, if you pass in num_labels = 1 you get a regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 10 of the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging face tasks\n",
    "\n",
    "[Hugging face tasks](https://huggingface.co/tasks) contains helpful starting points for a variety of tasks, including:\n",
    "\n",
    "* Text Classification (what we were doing here)\n",
    "\n",
    "* Question Answering (given a question and a text containing the answer, give the answer)\n",
    "\n",
    "* Text generation (Chat gpt)\n",
    "\n",
    "* .... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdl_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
