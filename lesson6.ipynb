{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 6 - Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from fastai.imports import *  # imports the usual suspects\n",
    "path = Path('data/titanic')\n",
    "df = pd.read_csv(path/'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "\n",
    "def proc_data(df):\n",
    "    df['Fare'] = df.Fare.fillna(0)\n",
    "    df.fillna(modes, inplace=True)  # fill missing values with mode\n",
    "    df['LogFare'] = np.log1p(df['Fare'])\n",
    "    df['Embarked'] = pd.Categorical(df.Embarked)\n",
    "    df['Sex'] = pd.Categorical(df.Sex)\n",
    "\n",
    "proc_data(df)\n",
    "\n",
    "# I am not bothering with the test data for now, i dont plan to submit this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=[\"Sex\",\"Embarked\"]\n",
    "conts=['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]\n",
    "dep=\"Survived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import random\n",
    "\n",
    "random.seed(42)\n",
    "trn_df,val_df = train_test_split(df, test_size=0.25)\n",
    "trn_df[cats] = trn_df[cats].apply(lambda x: x.cat.codes) # convert to codes \n",
    "val_df[cats] = val_df[cats].apply(lambda x: x.cat.codes) # convert to codes\n",
    "\n",
    "# Create x's and y's \n",
    "def xs_y(df):\n",
    "    xs = df[cats+conts].copy()\n",
    "    return xs,df[dep] if dep in df else None\n",
    "\n",
    "trn_xs,trn_y = xs_y(trn_df)\n",
    "val_xs,val_y = xs_y(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video lesson \n",
    "\n",
    "* First he goes through the 'manual' [OneR](https://link.springer.com/article/10.1023/A:1022631118932) again from last week to catch us up. \n",
    "\n",
    "* Then continues to work through [How random forests work](https://www.kaggle.com/code/jhoward/how-random-forests-really-work/)  \n",
    "\n",
    "    * Builds a decision tree one level deeper then 1 R, looking for the next split.\n",
    "\n",
    "    * Note that he is sitll  using the standard deviation * number of points in a leaf as a score (see notebook)\n",
    "\n",
    "    * Then on to using sklearn's decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "m = DecisionTreeClassifier(max_leaf_nodes=4).fit(trn_xs, trn_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"504pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 503.75 305.45\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301.45)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-301.45 499.75,-301.45 499.75,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f5ceb2\" stroke=\"black\" d=\"M295.5,-293C295.5,-293 195.5,-293 195.5,-293 189.5,-293 183.5,-287 183.5,-281 183.5,-281 183.5,-237 183.5,-237 183.5,-231 189.5,-225 195.5,-225 195.5,-225 295.5,-225 295.5,-225 301.5,-225 307.5,-231 307.5,-237 307.5,-237 307.5,-281 307.5,-281 307.5,-287 301.5,-293 295.5,-293\"/>\n",
       "<text text-anchor=\"start\" x=\"217\" y=\"-275.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Sex ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"214\" y=\"-260.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.47</text>\n",
       "<text text-anchor=\"start\" x=\"200.88\" y=\"-245.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 668</text>\n",
       "<text text-anchor=\"start\" x=\"191.5\" y=\"-230.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [415, 253]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#7ebfee\" stroke=\"black\" d=\"M224.75,-174C224.75,-174 132.25,-174 132.25,-174 126.25,-174 120.25,-168 120.25,-162 120.25,-162 120.25,-118 120.25,-118 120.25,-112 126.25,-106 132.25,-106 132.25,-106 224.75,-106 224.75,-106 230.75,-106 236.75,-112 236.75,-118 236.75,-118 236.75,-162 236.75,-162 236.75,-168 230.75,-174 224.75,-174\"/>\n",
       "<text text-anchor=\"start\" x=\"141.75\" y=\"-156.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n",
       "<text text-anchor=\"start\" x=\"147\" y=\"-141.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.38</text>\n",
       "<text text-anchor=\"start\" x=\"133.88\" y=\"-126.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 229</text>\n",
       "<text text-anchor=\"start\" x=\"128.25\" y=\"-111.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [59, 170]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M226.48,-224.79C219.27,-212.19 210.94,-197.65 203.27,-184.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206.33,-182.55 198.32,-175.61 200.25,-186.03 206.33,-182.55\"/>\n",
       "<text text-anchor=\"middle\" x=\"191.01\" y=\"-192.62\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#eb9e67\" stroke=\"black\" d=\"M359.75,-174C359.75,-174 267.25,-174 267.25,-174 261.25,-174 255.25,-168 255.25,-162 255.25,-162 255.25,-118 255.25,-118 255.25,-112 261.25,-106 267.25,-106 267.25,-106 359.75,-106 359.75,-106 365.75,-106 371.75,-112 371.75,-118 371.75,-118 371.75,-162 371.75,-162 371.75,-168 365.75,-174 359.75,-174\"/>\n",
       "<text text-anchor=\"start\" x=\"284.62\" y=\"-156.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 6.5</text>\n",
       "<text text-anchor=\"start\" x=\"282\" y=\"-141.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.31</text>\n",
       "<text text-anchor=\"start\" x=\"268.88\" y=\"-126.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 439</text>\n",
       "<text text-anchor=\"start\" x=\"263.25\" y=\"-111.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [356, 83]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M264.8,-224.79C272.2,-212.06 280.74,-197.37 288.58,-183.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"291.39,-186.01 293.39,-175.61 285.34,-182.49 291.39,-186.01\"/>\n",
       "<text text-anchor=\"middle\" x=\"300.55\" y=\"-192.66\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#40a0e6\" stroke=\"black\" d=\"M97,-56.5C97,-56.5 12,-56.5 12,-56.5 6,-56.5 0,-50.5 0,-44.5 0,-44.5 0,-15.5 0,-15.5 0,-9.5 6,-3.5 12,-3.5 12,-3.5 97,-3.5 97,-3.5 103,-3.5 109,-9.5 109,-15.5 109,-15.5 109,-44.5 109,-44.5 109,-50.5 103,-56.5 97,-56.5\"/>\n",
       "<text text-anchor=\"start\" x=\"23\" y=\"-39.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.06</text>\n",
       "<text text-anchor=\"start\" x=\"9.88\" y=\"-24.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-9.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 116]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.28,-105.72C125.17,-92.56 107.84,-77.46 92.73,-64.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"95.11,-61.73 85.27,-57.8 90.51,-67 95.11,-61.73\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#fffdfb\" stroke=\"black\" d=\"M224,-56.5C224,-56.5 139,-56.5 139,-56.5 133,-56.5 127,-50.5 127,-44.5 127,-44.5 127,-15.5 127,-15.5 127,-9.5 133,-3.5 139,-3.5 139,-3.5 224,-3.5 224,-3.5 230,-3.5 236,-9.5 236,-15.5 236,-15.5 236,-44.5 236,-44.5 236,-50.5 230,-56.5 224,-56.5\"/>\n",
       "<text text-anchor=\"start\" x=\"153.75\" y=\"-39.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"136.88\" y=\"-24.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 109</text>\n",
       "<text text-anchor=\"start\" x=\"135\" y=\"-9.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [55, 54]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.42,-105.72C179.76,-93.79 180.13,-80.27 180.47,-68.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.96,-68.41 180.74,-58.32 176.96,-68.22 183.96,-68.41\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#88c4ef\" stroke=\"black\" d=\"M349.25,-56.5C349.25,-56.5 271.75,-56.5 271.75,-56.5 265.75,-56.5 259.75,-50.5 259.75,-44.5 259.75,-44.5 259.75,-15.5 259.75,-15.5 259.75,-9.5 265.75,-3.5 271.75,-3.5 271.75,-3.5 349.25,-3.5 349.25,-3.5 355.25,-3.5 361.25,-9.5 361.25,-15.5 361.25,-15.5 361.25,-44.5 361.25,-44.5 361.25,-50.5 355.25,-56.5 349.25,-56.5\"/>\n",
       "<text text-anchor=\"start\" x=\"279\" y=\"-39.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.41</text>\n",
       "<text text-anchor=\"start\" x=\"269.62\" y=\"-24.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n",
       "<text text-anchor=\"start\" x=\"267.75\" y=\"-9.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 15]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.58,-105.72C312.24,-93.79 311.87,-80.27 311.53,-68.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"315.04,-68.22 311.26,-58.32 308.04,-68.41 315.04,-68.22\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#ea995f\" stroke=\"black\" d=\"M483.75,-56.5C483.75,-56.5 391.25,-56.5 391.25,-56.5 385.25,-56.5 379.25,-50.5 379.25,-44.5 379.25,-44.5 379.25,-15.5 379.25,-15.5 379.25,-9.5 385.25,-3.5 391.25,-3.5 391.25,-3.5 483.75,-3.5 483.75,-3.5 489.75,-3.5 495.75,-9.5 495.75,-15.5 495.75,-15.5 495.75,-44.5 495.75,-44.5 495.75,-50.5 489.75,-56.5 483.75,-56.5\"/>\n",
       "<text text-anchor=\"start\" x=\"406\" y=\"-39.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.27</text>\n",
       "<text text-anchor=\"start\" x=\"392.88\" y=\"-24.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 418</text>\n",
       "<text text-anchor=\"start\" x=\"387.25\" y=\"-9.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [350, 68]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M351.72,-105.72C366.83,-92.56 384.16,-77.46 399.27,-64.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"401.49,-67 406.73,-57.8 396.89,-61.73 401.49,-67\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x32a351010>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import graphviz\n",
    "\n",
    "def draw_tree(t, df, size=10, ratio=0.6, precision=2, **kwargs):\n",
    "    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True, rounded=True,\n",
    "                      special_characters=True, rotate=False, precision=precision, **kwargs)\n",
    "    return graphviz.Source(re.sub('Tree {', f'Tree {{ size={size}; ratio={ratio}', s))\n",
    "\n",
    "\n",
    "draw_tree(m, trn_xs, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Decision trees like this are very useful for understanding the data -- quick picture of key variables\n",
    "\n",
    "* gini is another impurity measure, and the one used by default in sklearn. It is a measure of statistical dispersion, intended to represent the probability that two elements chosen randomly from the dataset would be incorrectly labeled if they were randomly labeled according to the distribution of labels in the dataset. \n",
    "\n",
    "$$\n",
    "G = 1 - \\sum_i p_i^2\n",
    "$$\n",
    "This score is cacluated for each leaf node, summing over the number of classes. $p_i$ is the fraction in that node of class i.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok how does this do on validation set?  Jeremy uses mean absolute error, which is the same as one miuse the accuracy here since the tree only predicts 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2242152466367713"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(val_y, m.predict(val_xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its wrong 22% of the time.  Lets try a deeper tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18385650224215247"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DecisionTreeClassifier(min_samples_leaf=50)\n",
    "m.fit(trn_xs, trn_y)\n",
    "mean_absolute_error(val_y, m.predict(val_xs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks on categorical variables\n",
    "\n",
    "* You don't need to create dummies for trees, since they can split on the categories directly.\n",
    "\n",
    "* For small number of categories, it can be more efficient to use one-hot encoding to avoid having to split multiple times on the same variable to get out an important category that is in the middle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests\n",
    "\n",
    "* We can't keep making the tree deeper, eventually it will over fit (memorize the data) with only 1 data point in each terminal node! \n",
    "\n",
    "* AN alternative is to use bagging, which is to train multiple trees on different subsets of the data and average the results.  Random forests also use random subset of features for each split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19282511210762332"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(100, min_samples_leaf=10)\n",
    "rf.fit(trn_xs, trn_y);\n",
    "mean_absolute_error(val_y, rf.predict(val_xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests also have a feature to help find which features are important.  It is the average of the decrease in impurity for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(dict(cols=trn_xs.columns, imp=m.feature_importances_)).plot('cols', 'imp', 'barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video now goes into the chapter notebook  \n",
    "\n",
    "See below for my highlights of chapter 9.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  out-of-bag error\n",
    "\n",
    "* The out-of-bag error is the error on the data that was not used to train the tree.  This is a good estimate of the error on new data.  It is the average of the error on each tree for the data that was not used to train that tree.\n",
    "\n",
    "* Built in to sklearn as well. But you have to specify oob_score=True when you create the RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811377245508982"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(100, min_samples_leaf=10, oob_score=True)\n",
    "rf.fit(trn_xs, trn_y);\n",
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that oob_prediction_ is no longer available for RandomForestClassifier. However it is still available for RandomForestRegressor.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ALLWAYS start a tabular data project with a random forest to get a sense of the data.  It is a good way to get a sense of the data and what is important!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partial Dependence \n",
    "\n",
    "* What is the relationship between features and dependant variables.  This is usually computed for a small set of features (one or two), marginalizing over the other features .  In practice this means, for each value of the selected variable, predicting with the model for each row using the  existing values for the other variables (those being marginalized over.) Average over the other.\n",
    "\n",
    "* Can be done with any machine learning model. \n",
    "\n",
    "* `sklearn.inspection` has `partial_dependence` (no longer has `plot_partial_dependence`, but there is `PartialDependenceDisplay` class.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient boosting\n",
    "\n",
    "* Generally fits better, but is a bit more finicky (you can overfit)\n",
    "\n",
    "* See [How to explain gradient boosting](https://explained.ai/gradient-boosting/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More highlights Chapter 9\n",
    "\n",
    "*  If OOB significantly better then validation error, consider that something beyond generalization error is causing underfitting.\n",
    "\n",
    "* Interpretation\n",
    "    * Standard deviation of the (random) tree results give a measure of confidence on the trees prediction\n",
    "    * SKlearn can provide feature importance (computed by looking at how much the model improved when splitting on those features).\n",
    "    * Feature importance can be used to select unimportant features to remove and simplify the model.\n",
    "    * `cluster_columns`  can be used to identify redundant columns to try and remove (checking `oob` score to see if it is effected ).  `cluster_columns` is defined in the books `utils.py`  as:\n",
    "\n",
    "        ```\n",
    "        from scipy.cluster import hierarchy as hc\n",
    "\n",
    "        def cluster_columns(df, figsize=(10,6), font_size=12):\n",
    "            corr = np.round(scipy.stats.spearmanr(df).correlation, 4)\n",
    "            corr_condensed = hc.distance.squareform(1-corr)\n",
    "            z = hc.linkage(corr_condensed, method='average')\n",
    "            fig = plt.figure(figsize=figsize)\n",
    "            hc.dendrogram(z, labels=df.columns, orientation='left', leaf_font_size=font_size)\n",
    "            plt.show()\n",
    "        ```\n",
    "    * Partial dependance plots help understand how the results depend on each variable, all other variables held constant. (Counterfactual!)\n",
    "    * Library `treeinterpreter` can be used to show for predicting a particular row of data, what were the most important factors, and how did they influence the prediction.  Basically feature importance but for a particular prediction.  `treeintepreter` library can do this automatically.\n",
    "\n",
    "\n",
    "* Data Leakage: Be careful, sometime data is missing for a reason, and that reason might be related to the value you are trying to predict!!  Models can help... are some variables more predictive the you expect? Do some variables partial dependance not make sense?\n",
    "\n",
    "\n",
    "* Random forests and related methods are bad at extrapolation (just predict constant values outside the domain fo the data)\n",
    "   * Book chapter shows a cool trick to detect issues like this: Train a random forest to predict if a data point is in the test set or validation set.  \n",
    "   * This can uncover \"domain_shift\" issues, for example in the chapter, machine_id and sales_id both encode the date of sale (albeit imperfectly) and so predict well (for this case) train vs validation.\n",
    "\n",
    "* Fast.ai's `TabularLearner` was demonstrated next. This is by default a two hidden layer neural network that uses embedding for the categorical variables. It does slightly better.  Even better is ensembling this with the forest results! Note: Default is hidden layers are 100,200 and default embedding is `min(600, 1.6*n_cat**0.56)`\n",
    "\n",
    "* Boosting is mentioned breifly, and that XGBoost is the state of the art at the time of writing. ALso that boosting tends to be more susceptable to overfitting and can be more sensitive to hyperparameters.\n",
    "\n",
    "* Embeddings obtained by training a neural net (perhaps on another task!) can be used as input features for your Random forest or other machine learning methods. (Guo and Berkhahn 2016, Entity Embeddings of Categorical Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road to the top\n",
    "\n",
    "Jeremy walked through his [Road to the top part 1](https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1) and [part 2](https://www.kaggle.com/code/jhoward/small-models-road-to-the-top-part-2/) notebooks where he hit the top of the leaderboard on rice paddy disease recognition.\n",
    "\n",
    "Highlights:\n",
    "\n",
    "* fastkaggle - automates some aspects of setting up a kaggle notebook. \n",
    "\n",
    "* Focus on creating an effective validation data set and *iterate* to find solutions that improve results on the validation set   (i worry here about overfitting the validation data though!)\n",
    "\n",
    "* Build a model as soon as you can, to help you understand the data! \n",
    "\n",
    "* Test time augmentation can help predictions in vision models. (ensembling!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdl_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
